{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import boto3\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'demo-saeed'\n",
    "prefix = 'fraudcredit-keras'\n",
    "dataset_name = 'creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'data/train.csv')).upload_file('data/creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input = sagemaker_session.upload_data('data', key_prefix=\"{}/{}/{}\".format(bucket_name, prefix, 'data') )\n",
    "# train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://demo-saeed/fraudcredit-keras/data',\n",
       "   'S3DataDistributionType': 'FullyReplicated'}},\n",
       " 'ContentType': 'csv'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location = 's3://{}/{}/{}'.format(bucket, prefix, 'data',dataset_name)\n",
    "s3_input_train = sagemaker.s3_input(s3_data = data_location, content_type='csv')\n",
    "s3_input_train.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-keras/data/train.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = 's3://demo-saeed/fraudcredit-keras/data/train.csv'\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(train_input, sep=',',  nrows=1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='main.py', \n",
    "                          role=role,\n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='local',\n",
    "                          framework_version='1.12', \n",
    "                          py_version='py3',\n",
    "                          script_mode=True,\n",
    "                          hyperparameters={'epochs': 1}\n",
    "                         )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpeikeq3o0_algo-1-h7wg0_1 ... \n",
      "\u001b[1BAttaching to tmpeikeq3o0_algo-1-h7wg0_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m 2020-03-08 18:56:14,363 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m 2020-03-08 18:56:14,369 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m 2020-03-08 18:56:14,540 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m 2020-03-08 18:56:14,554 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m 2020-03-08 18:56:14,563 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"current_host\": \"algo-1-h7wg0\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         \"algo-1-h7wg0\"\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         \"model_dir\": \"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/model\"\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m             \"ContentType\": \"csv\"\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"job_name\": \"sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"master_hostname\": \"algo-1-h7wg0\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"module_name\": \"main\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         \"current_host\": \"algo-1-h7wg0\",\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m             \"algo-1-h7wg0\"\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m     \"user_entry_point\": \"main.py\"\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_HOSTS=[\"algo-1-h7wg0\"]\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_HPS={\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/model\"}\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_USER_ENTRY_POINT=main.py\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-h7wg0\",\"hosts\":[\"algo-1-h7wg0\"]}\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_CURRENT_HOST=algo-1-h7wg0\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_MODULE_NAME=main\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-h7wg0\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-h7wg0\"],\"hyperparameters\":{\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802\",\"log_level\":20,\"master_hostname\":\"algo-1-h7wg0\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-h7wg0\",\"hosts\":[\"algo-1-h7wg0\"]},\"user_entry_point\":\"main.py\"}\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/model\"]\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/model\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m /usr/bin/python main.py --epochs 1 --model_dir s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/model\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Using TensorFlow backend.\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m (227451, 30)\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Train on 227451 samples, validate on 56962 samples\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Epoch 1/2\n",
      "227451/227451 [==============================] - 15s 64us/step - loss: 374844622.9805 - acc: 3.5612e-04 - val_loss: 375362771.0965 - val_acc: 3.3356e-04\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Epoch 2/2\n",
      "227451/227451 [==============================] - 14s 61us/step - loss: 374844510.6152 - acc: 3.6491e-04 - val_loss: 375362717.6344 - val_acc: 3.3356e-04\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m Pass your op to the equivalent parameter main_op instead.\n",
      "\u001b[36malgo-1-h7wg0_1  |\u001b[0m 2020-03-08 18:56:55,729 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpeikeq3o0_algo-1-h7wg0_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "tf_estimator.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-08-18-55-29-802/model'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_estimator.model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediciton using endpoint high-level sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmp6n1kw9a9_algo-1-gccm2_1\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:starting services\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:using default model name: model\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:tensorflow serving model config: \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m model_config_list: {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   config: {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     name: \"model\",\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     base_path: \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     model_platform: \"tensorflow\"\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:nginx config: \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m load_module modules/ngx_http_js_module.so;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m worker_processes auto;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m daemon off;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m error_log  /dev/stderr info;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m events {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m http {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   default_type application/json;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   js_include tensorflow-serving.js;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   upstream tfs_upstream {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     server localhost:8501;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   upstream gunicorn_upstream {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   server {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     client_body_buffer_size 100m;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     subrequest_output_buffer_size 100m;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     set $tfs_version 1.12;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     set $default_tfs_model model;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     location /tfs {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         rewrite ^/tfs/(.*) /$1  break;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         proxy_redirect off;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         proxy_pass_request_headers off;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         proxy_set_header Content-Type 'application/json';\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         proxy_set_header Accept 'application/json';\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         proxy_pass http://tfs_upstream;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     location /ping {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         js_content ping;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     location /invocations {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     location ~ ^/models/(.*)/invoke {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     location /models {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         proxy_pass http://gunicorn_upstream/models;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     location / {\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m         return 404 '{\"error\": \"Not Found\"}';\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:tensorflow version info:\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m TensorFlow ModelServer: 1.12.0-rc0+dev.sha.87470f0\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m TensorFlow Library: 1.12.0\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:tensorflow serving command: tensorflow_model_server --port=9000 --rest_api_port=8501 --model_config_file=/sagemaker/model-config.cfg \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:started tensorflow serving (pid: 8)\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:nginx version info:\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m nginx version: nginx/1.16.1\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m built by gcc 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11) \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m built with OpenSSL 1.0.2g  1 Mar 2016\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m TLS SNI support enabled\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m INFO:__main__:started nginx (pid: 10)\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: using the \"epoll\" event method\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: nginx/1.16.1\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: built by gcc 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11) \n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: OS: Linux 4.14.165-102.185.amzn1.x86_64\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: getrlimit(RLIMIT_NOFILE): 1024:4096\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker processes\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker process 11\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker process 12\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker process 13\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker process 14\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker process 15\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker process 16\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker process 17\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:52:34 [notice] 10#10: start worker process 18\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:34.928853: I tensorflow_serving/model_servers/server_core.cc:461] Adding/updating models.\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:34.928890: I tensorflow_serving/model_servers/server_core.cc:558]  (Re-)adding model: model\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.029190: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: model version: 1}\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.029226: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.029248: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.029273: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:363] Attempting to load native SavedModelBundle in bundle-shim from: /opt/ml/model/1\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.029292: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/1\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.035737: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.042040: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.069432: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:162] Restoring SavedModel bundle.\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.084048: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:138] Running MainOp with key legacy_init_op on SavedModel bundle.\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.084083: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:259] SavedModel load for tags { serve }; Status: success. Took 54785 microseconds.\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.084117: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:83] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.084360: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.086842: I tensorflow_serving/model_servers/server.cc:286] Running gRPC ModelServer at 0.0.0.0:9000 ...\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m [warn] getaddrinfo: address family for nodename not supported\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020-03-06 21:52:35.088380: I tensorflow_serving/model_servers/server.cc:302] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m [evhttp_server.cc : 237] RAW: Entering the event loop ...\n",
      "!\u001b[36malgo-1-gccm2_1  |\u001b[0m 172.18.0.1 - - [06/Mar/2020:21:52:38 +0000] \"GET /ping HTTP/1.1\" 200 3 \"-\" \"-\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tf_endpoint_name = 'keras-tf-fmnist-'+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "#tf_predictor = tf_estimator.deploy(initial_instance_count=1,\n",
    "#                                   instance_type='ml.p2.xlarge')      # $1.361/hour in eu-west-1\n",
    "\n",
    "tf_predictor = tf_estimator.deploy(initial_instance_count=1,\n",
    "                         instance_type='local',        # $0.134/hour in eu-west-1\n",
    "                         #accelerator_type='ml.eia1.medium',  # + $0.140/hour in eu-west-1\n",
    "                         endpoint_name=tf_endpoint_name)     # = 80% discount!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798, 29)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 42\n",
    "LABELS = [\"Normal\", \"Fraud\"]\n",
    "data = df.drop(['Time'], axis=1)\n",
    "\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train = X_train[X_train.Class == 0]\n",
    "X_train = X_train.drop(['Class'], axis=1)\n",
    "\n",
    "y_test = X_test['Class']\n",
    "X_test = X_test.drop(['Class'], axis=1)\n",
    "\n",
    "batch_file = 'batch_data.csv'\n",
    "X_test.to_csv(batch_file,index=False,header=False)\n",
    "#sess.upload_data(batch_file, key_prefix='{}/batch'.format(prefix))\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'batch/batch_data.csv')).upload_file('batch_data.csv')\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = X_test[0:2,]\n",
    "# payload = json.dumps({'inputs':tt.tolist()})\n",
    "# payload\n",
    "# tf_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_predictor.predict({'instances': X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 2020/03/06 21:53:14 [warn] 18#18: *2 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 172.18.0.1, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:8501/v1/models/model:predict\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-gccm2_1  |\u001b[0m 172.18.0.1 - - [06/Mar/2020:21:53:14 +0000] \"POST /invocations HTTP/1.1\" 200 37731 \"-\" \"-\"\n"
     ]
    }
   ],
   "source": [
    "predictions = tf_predictor.predict(X_test)['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.225959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.088699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.612147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.138237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.190693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.221506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0.123476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1.319569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.161115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.763574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>2.154975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.120665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.176503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.325102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>0.170242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.242195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.272413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0.637557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0.562604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.304396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     reconstruction_error  true_class\n",
       "521              0.225959           0\n",
       "737              0.088699           0\n",
       "740              0.612147           0\n",
       "660              0.138237           0\n",
       "411              0.190693           0\n",
       "678              0.221506           0\n",
       "626              0.123476           0\n",
       "513              1.319569           0\n",
       "859              0.161115           0\n",
       "136              0.763574           0\n",
       "811              2.154975           0\n",
       "76               0.120665           0\n",
       "636              0.176503           0\n",
       "973              0.325102           0\n",
       "938              0.170242           0\n",
       "899              0.242195           0\n",
       "280              0.272413           0\n",
       "883              0.637557           0\n",
       "761              0.562604           0\n",
       "319              0.304396           0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediciton using Tensorflow Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Saeed-demo/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-06-16-23-30-671/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-03-06-16-23-30-671/model.tar.gz model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from SavedModels/autoencodermodel/1/variables/variables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'serving_default': inputs {\n",
       "  key: \"inputs\"\n",
       "  value {\n",
       "    name: \"input_1_1:0\"\n",
       "    dtype: DT_FLOAT\n",
       "    tensor_shape {\n",
       "      dim {\n",
       "        size: -1\n",
       "      }\n",
       "      dim {\n",
       "        size: 29\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "outputs {\n",
       "  key: \"dense_4_1/Relu:0\"\n",
       "  value {\n",
       "    name: \"dense_4_1/Relu:0\"\n",
       "    dtype: DT_FLOAT\n",
       "    tensor_shape {\n",
       "      dim {\n",
       "        size: -1\n",
       "      }\n",
       "      dim {\n",
       "        size: 29\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "method_name: \"tensorflow/serving/predict\"\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "loaded = tf.saved_model.load(export_dir='SavedModels/autoencodermodel/1/', tags={'serve'},sess=sess )\n",
    "loaded.signature_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['inputs'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 29)\n",
      "        name: input_1_1:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_4_1/Relu:0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 29)\n",
      "        name: dense_4_1/Relu:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir SavedModels/autoencodermodel/1/ --tag_set serve --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=mobilenet1 \\\n",
    "  --model_base_path=\"SavedModels/autoencodermodel/1\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07193637, -1.60199934, -0.6061928 , ..., -0.0895    ,\n",
       "         0.09558394,  2.71879153],\n",
       "       [ 1.18948241,  0.23724716,  0.24498043, ...,  0.02357161,\n",
       "         0.01612106, -0.30105079],\n",
       "       [-0.84808655, -0.57344051,  1.4913986 , ..., -0.39218566,\n",
       "        -0.52142946,  0.74976351],\n",
       "       ...,\n",
       "       [ 0.95127828, -0.65772959,  1.70188353, ...,  0.10681691,\n",
       "         0.04088053, -0.04503868],\n",
       "       [-0.38672597,  0.17256499,  0.73258264, ...,  0.11404772,\n",
       "         0.13568659, -0.06106615],\n",
       "       [-0.57152075,  1.07160045,  1.28011025, ...,  0.07164145,\n",
       "        -0.17551047, -0.30260011]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import json\n",
    "# import numpy\n",
    "# import requests\n",
    "# data = json.dumps({\"signature_name\": \"serving_default\",\n",
    "#                    \"instances\": X_test.tolist()})\n",
    "# headers = {\"content-type\": \"application/json\"}\n",
    "# json_response = requests.post('http://localhost:8501/v1/models/mobilenet1:predict',\n",
    "#                               data=data, headers=headers)\n",
    "# predictions = numpy.array(json.loads(json_response.text)[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'serving'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p tmp/tfserving\n",
    "cd tmp/tfserving\n",
    "git clone --depth=1 https://github.com/tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest: Pulling from tensorflow/serving\n",
      "Digest: sha256:ea44bf657f8cff7b07df12361749ea94628185352836bb08065345f5c8284bae\n",
      "Status: Image is up to date for tensorflow/serving:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd tmp/tfserving\n",
    "docker pull tensorflow/serving:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Saeed-demo/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'tensorflow/serving:latest' locally\n",
      "latest: Pulling from tensorflow/serving\n",
      "\n",
      "\u001b[1Ba4a261c9: Pulling fs layer \n",
      "\u001b[1B20cdee96: Pulling fs layer \n",
      "\u001b[1B60e1d0de: Pulling fs layer \n",
      "\u001b[1B7668deea: Pulling fs layer \n",
      "\u001b[1Bb5699598: Pulling fs layer \n",
      "\u001b[1B8f5dbe31: Pulling fs layer \n",
      "\u001b[1B011e11a2: Pulling fs layer \n",
      "\u001b[1B075f0126: Pull complete  280B/280BMBBB\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[KDigest: sha256:ea44bf657f8cff7b07df12361749ea94628185352836bb08065345f5c8284bae\n",
      "Status: Downloaded newer image for tensorflow/serving:latest\n",
      "2020-03-08 19:04:51.882717: I tensorflow_serving/model_servers/server.cc:86] Building single TensorFlow model file config:  model_name: autoencodermodel model_base_path: /home/ec2-user/SageMaker/Saeed-demo/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras/SavedModels/autoencodermodel\n",
      "2020-03-08 19:04:51.882852: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\n",
      "2020-03-08 19:04:51.882864: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: autoencodermodel\n",
      "2020-03-08 19:04:51.983127: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: autoencodermodel version: 1}\n",
      "2020-03-08 19:04:51.983151: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: autoencodermodel version: 1}\n",
      "2020-03-08 19:04:51.983165: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: autoencodermodel version: 1}\n",
      "2020-03-08 19:04:51.983180: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /home/ec2-user/SageMaker/Saeed-demo/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras/SavedModels/autoencodermodel/1\n",
      "2020-03-08 19:04:51.988023: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "2020-03-08 19:04:51.988046: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /home/ec2-user/SageMaker/Saeed-demo/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras/SavedModels/autoencodermodel/1\n",
      "2020-03-08 19:04:51.988125: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-03-08 19:04:52.013652: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\n",
      "2020-03-08 19:04:52.053844: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 70660 microseconds.\n",
      "2020-03-08 19:04:52.055023: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /home/ec2-user/SageMaker/Saeed-demo/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras/SavedModels/autoencodermodel/1/assets.extra/tf_serving_warmup_requests\n",
      "2020-03-08 19:04:52.056252: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: autoencodermodel version: 1}\n",
      "2020-03-08 19:04:52.059550: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2020-03-08 19:04:52.062037: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm -p 8501:8501 \\\n",
    "    --mount type=bind,source=$(pwd),target=$(pwd) \\\n",
    "    -e MODEL_BASE_PATH=$(pwd)/SavedModels \\\n",
    "    -e MODEL_NAME=autoencodermodel -t tensorflow/serving:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                       COMMAND                  CREATED             STATUS              PORTS                              NAMES\n",
      "aaf66c759b30        tensorflow/serving:latest   \"/usr/bin/tf_servingâ€¦\"   28 seconds ago      Up 23 seconds       8500/tcp, 0.0.0.0:8501->8501/tcp   optimistic_neumann\n"
     ]
    }
   ],
   "source": [
    "!docker ps\n",
    "#!docker kill 96c5dc662795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"model_version_status\": [\n",
      "  {\n",
      "   \"version\": \"1\",\n",
      "   \"state\": \"AVAILABLE\",\n",
      "   \"status\": {\n",
      "    \"error_code\": \"OK\",\n",
      "    \"error_message\": \"\"\n",
      "   }\n",
      "  }\n",
      " ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   154  100   154    0     0  11000      0 --:--:-- --:--:-- --:--:-- 11000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl http://localhost:8501/v1/models/autoencodermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[1.0715723, 0.0, 2.18216205, 7.8084, 0.76329577, 2.31510925, 0.0, 0.0, 0.0, 0.53235352, 1.37354612, 0.0, 0.0, 0.0, 0.901465476, 0.440022677, 1.00044906, 0.0, 1.07490849, 0.0, 0.0, 0.0377479494, 0.0969904065, 0.0, 0.0, 0.800467908, 0.0, 0.0, 0.0], [1.0715723, 0.0, 2.18216205, 7.8084, 0.76329577, 2.31510925, 0.0, 0.0, 0.0, 0.53235352, 1.37354612, 0.0, 0.0, 0.0, 0.901465476, 0.440022677, 1.00044906, 0.0, 1.07490849, 0.0, 0.0, 0.0377479494, 0.0969904065, 0.0, 0.0, 0.800467908, 0.0, 0.0, 0.0]\n",
      "    ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl -d '{\"instances\": [[1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0], \\\n",
    "[1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0]]}' -X POST http://localhost:8501/v1/models/autoencodermodel:predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '{\"instances\": [[1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0], \\\n",
    "[1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0,0.0, 1.0,2.0,5.0,2.0]]}'\n",
    "# files = {\n",
    "#     'image_file': open('/home/hellouser/Downloads/infer/Users/User01/Images/tiles/999/00.jpg', 'rb')\n",
    "# }\n",
    "\n",
    "url = 'http://localhost:8501/v1/models/autoencodermodel:predict'\n",
    "r = requests.post(url=url, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[1.0715723, 0.0, 2.18216205, 7.8084, 0.76329577, 2.31510925, 0.0, 0.0, 0.0, 0.53235352, 1.37354612, 0.0, 0.0, 0.0, 0.901465476, 0.440022677, 1.00044906, 0.0, 1.07490849, 0.0, 0.0, 0.0377479494, 0.0969904065, 0.0, 0.0, 0.800467908, 0.0, 0.0, 0.0], [1.0715723, 0.0, 2.18216205, 7.8084, 0.76329577, 2.31510925, 0.0, 0.0, 0.0, 0.53235352, 1.37354612, 0.0, 0.0, 0.0, 0.901465476, 0.440022677, 1.00044906, 0.0, 1.07490849, 0.0, 0.0, 0.0377479494, 0.0969904065, 0.0, 0.0, 0.800467908, 0.0, 0.0, 0.0]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-keras/batch_output/'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path='s3://{}/{}/batch_output/'.format(bucket, prefix)\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmppenc80r9_algo-1-y7998_1\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:starting services\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:using default model name: model\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:tensorflow serving model config: \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m model_config_list: {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   config: {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     name: \"model\",\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     base_path: \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     model_platform: \"tensorflow\"\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:nginx config: \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m load_module modules/ngx_http_js_module.so;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m worker_processes auto;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m daemon off;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m error_log  /dev/stderr info;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m events {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m http {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   default_type application/json;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   js_include tensorflow-serving.js;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   upstream tfs_upstream {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     server localhost:8501;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   upstream gunicorn_upstream {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   server {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     client_body_buffer_size 100m;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     subrequest_output_buffer_size 100m;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     set $tfs_version 1.12;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     set $default_tfs_model model;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     location /tfs {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         rewrite ^/tfs/(.*) /$1  break;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         proxy_redirect off;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         proxy_pass_request_headers off;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         proxy_set_header Content-Type 'application/json';\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         proxy_set_header Accept 'application/json';\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         proxy_pass http://tfs_upstream;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     location /ping {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         js_content ping;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     location /invocations {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     location ~ ^/models/(.*)/invoke {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         js_content invocations;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     location /models {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         proxy_pass http://gunicorn_upstream/models;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     location / {\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m         return 404 '{\"error\": \"Not Found\"}';\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:tensorflow version info:\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m TensorFlow ModelServer: 1.12.0-rc0+dev.sha.87470f0\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m TensorFlow Library: 1.12.0\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:tensorflow serving command: tensorflow_model_server --port=9000 --rest_api_port=8501 --model_config_file=/sagemaker/model-config.cfg \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:started tensorflow serving (pid: 8)\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:nginx version info:\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m nginx version: nginx/1.16.1\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m built by gcc 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11) \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m built with OpenSSL 1.0.2g  1 Mar 2016\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m TLS SNI support enabled\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m INFO:__main__:started nginx (pid: 10)\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: using the \"epoll\" event method\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: nginx/1.16.1\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: built by gcc 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11) \n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: OS: Linux 4.14.165-102.185.amzn1.x86_64\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: getrlimit(RLIMIT_NOFILE): 1024:4096\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker processes\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker process 11\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker process 12\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker process 13\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker process 14\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker process 15\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker process 16\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker process 17\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:19 [notice] 10#10: start worker process 18\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.677346: I tensorflow_serving/model_servers/server_core.cc:461] Adding/updating models.\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.677378: I tensorflow_serving/model_servers/server_core.cc:558]  (Re-)adding model: model\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.777670: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: model version: 1}\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.777698: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.777720: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.777743: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:363] Attempting to load native SavedModelBundle in bundle-shim from: /opt/ml/model/1\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.777758: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/1\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.783692: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.789850: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.815803: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:162] Restoring SavedModel bundle.\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.830143: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:138] Running MainOp with key legacy_init_op on SavedModel bundle.\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.830176: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:259] SavedModel load for tags { serve }; Status: success. Took 52413 microseconds.\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.830210: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:83] No warmup data file found at /opt/ml/model/1/assets.extra/tf_serving_warmup_requests\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.830458: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: model version: 1}\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.833095: I tensorflow_serving/model_servers/server.cc:286] Running gRPC ModelServer at 0.0.0.0:9000 ...\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m [warn] getaddrinfo: address family for nodename not supported\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020-03-06 22:03:19.834828: I tensorflow_serving/model_servers/server.cc:302] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m [evhttp_server.cc : 237] RAW: Entering the event loop ...\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 172.18.0.1 - - [06/Mar/2020:22:03:23 +0000] \"GET /ping HTTP/1.1\" 200 3 \"-\" \"-\"\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 172.18.0.1 - - [06/Mar/2020:22:03:23 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"-\"\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:23 [info] 16#16: *1 client 172.18.0.1 closed keepalive connection\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 2020/03/06 22:03:23 [warn] 16#16: *3 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: 172.18.0.1, server: , request: \"POST /invocations HTTP/1.1\", subrequest: \"/v1/models/model:predict\", upstream: \"http://127.0.0.1:8501/v1/models/model:predict\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-y7998_1  |\u001b[0m 172.18.0.1 - - [06/Mar/2020:22:03:23 +0000] \"POST /invocations HTTP/1.1\" 200 37731 \"-\" \"-\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "."
     ]
    }
   ],
   "source": [
    "sm_transformer = tf_estimator.transformer(1, 'local', output_path='s3://{}/{}/batch_output/'.format(bucket, prefix))\n",
    "# start a transform job\n",
    "input_location = 's3://{}/{}/batch/{}'.format(bucket, prefix, 'batch_data.csv') # use input data without ID column\n",
    "sm_transformer.transform(input_location, content_type='text/csv', split_type='Line')\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "\n",
    "    bucket_name = parsed_url.netloc\n",
    "\n",
    "    prefix = parsed_url.path[1:]\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.61166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.260130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.063055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.951820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.02960</td>\n",
       "      <td>0.226272</td>\n",
       "      <td>0.324172</td>\n",
       "      <td>1.03954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.19246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.318160</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.789449</td>\n",
       "      <td>0.109775</td>\n",
       "      <td>1.252820</td>\n",
       "      <td>0.362922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08857</td>\n",
       "      <td>0.141208</td>\n",
       "      <td>0.205083</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081515</td>\n",
       "      <td>0.07221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.534320</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203742</td>\n",
       "      <td>0.106238</td>\n",
       "      <td>0.076987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342895</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2        3         4         5         6   \\\n",
       "0  0.00000  0.000000  0.000000  1.61166  0.000000  0.000000  1.260130   \n",
       "1  1.02960  0.226272  0.324172  1.03954  0.000000  0.000000  0.000000   \n",
       "2  0.00000  0.000000  1.318160  0.00000  0.789449  0.109775  1.252820   \n",
       "3  1.08857  0.141208  0.205083  0.00000  0.000000  0.000000  0.000000   \n",
       "4  0.00000  0.000000  2.534320  0.00000  0.000000  0.000000  0.203742   \n",
       "\n",
       "         7         8    9   ...   19   20        21   22        23       24  \\\n",
       "0  0.000000  0.058937  0.0  ...  0.0  0.0  0.000000  0.0  0.000000  0.00000   \n",
       "1  0.000000  0.193701  0.0  ...  0.0  0.0  0.000000  0.0  0.000000  0.19246   \n",
       "2  0.362922  0.000000  0.0  ...  0.0  0.0  0.299968  0.0  0.000000  0.00000   \n",
       "3  0.000000  0.210598  0.0  ...  0.0  0.0  0.000000  0.0  0.081515  0.07221   \n",
       "4  0.106238  0.076987  0.0  ...  0.0  0.0  0.328653  0.0  0.342895  0.00000   \n",
       "\n",
       "         25   26   27        28  \n",
       "0  0.063055  0.0  0.0  2.951820  \n",
       "1  0.000000  0.0  0.0  0.000000  \n",
       "2  0.000000  0.0  0.0  0.520986  \n",
       "3  0.000000  0.0  0.0  0.000000  \n",
       "4  0.000000  0.0  0.0  0.000000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_csv_output_from_s3('s3://demo-saeed/fraudcredit-keras/batch_output/sagemaker-tensorflow-scriptmode-2020-03-2020-03-06-22-03-18-147', 'batch_data.csv.out')\n",
    "j =json.loads(output)\n",
    "n =j['predictions']\n",
    "df = pd.DataFrame.from_records(n)\n",
    "df.head()\n",
    "#output_df = pd.read_csv(j['predictions'], sep=\",\", header=None)\n",
    "# output_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5de8b9368b8f\n",
      "d52325faf8c3\n",
      "e52b55e755a7\n",
      "166773913f56\n",
      "1d5df8bb1af1\n",
      "8d13dd2e4878\n",
      "5c9c67930d9a\n"
     ]
    }
   ],
   "source": [
    "#!docker rm $(docker ps -a -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
